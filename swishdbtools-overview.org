#+TITLE:swishdbtools overview 
#+AUTHOR: Ivan Hanigan
#+email: ivan.hanigan@anu.edu.au
#+LaTeX_CLASS: article
#+LaTeX_CLASS_OPTIONS: [a4paper]
#+LATEX: \tableofcontents
-----

* Introduction
* functions
** load2postgres
*** test-load2postgres
#+name:test-load2postgres
#+begin_src R :session *R* :tangle tests/test-load2postgres.r :exports none :eval no
  ################################################################
  # name:test-load2postgres
  source("R/load2postgres.r")
  #### from subset man page ####
  head(subset(airquality, Temp > 80, select = c(Ozone, Temp)))
  str(airquality)
  tempdata <- airquality
  names(tempdata) <- tolower(names(tempdata))
  names(tempdata) <- gsub('\\.', '_',names(tempdata))
  str(tempdata)
  # dbWriteTable(ch, 'airquality', tempdata)
  write.csv(tempdata, 'airquality.csv', row.names=F, na = "")
  # rm(tempdata)
  require(swishdbtools)
  if(!exists('p'))
  {
    p <- getPassword()
  }
  ch <- connect2postgres('115.146.84.135', db='ewedb',
                         user='gislibrary', p=p)
  dbSendQuery(ch, 'drop table airquality')
  load2postgres('airquality.csv','public', 'airquality', pguser =
                'gislibrary', ip = '115.146.84.135', db='ewedb', print = F)
  
#+end_src

*** R-load2postgres
#+name:load2postgres
#+begin_src R :session *R* :tangle R/load2postgres.r :exports none :eval no
################################################################
# name:load2postgres
# tools for loading data to postgres
# Joseph Guillame and Ivan Hanigan
# original by Joe 24/3/2009

# TO DO:
## set the vacuum automatically when printcopy=F
## on linux replace the 'type' command with 'cat'

# load_newtable_to_postgres = Convert to csv and load to postgres
# pk as either column names as they appear at the end or column indices

# inspired from
#odbc_dsn="pg"
#require(RODBC)
#con<-odbcConnect(odbc_dsn,"postgres","test",case="postgresql")
#sqlSave(con,data[0,],test=TRUE,verbose=TRUE)
#close(con)

# source file could be
#source_file=paste("E'", csvfilename,"'",sep="")


# if (!file.exists('C:/pgutils/psql.exe')) {
# dir.create('c:/pgutils')
# download.file("http://alliance.anu.edu.au/access/content/group/4e0f55f1-b540-456a-000a-24730b59fccb/pgutils.zip","c:/pgutils/pgutils.zip",mode="wb")
# unzip("c:/pgutils/pgutils.zip",exdir="C:/pgutils")
# }
# not working
# print('please download http://alliance.anu.edu.au/access/content/group/4e0f55f1-b540-456a-000a-24730b59fccb/pgutils.zip')

load2postgres <- function(inputfilepath,schema,tablename,pk=NULL,header=TRUE,printcopy=TRUE,sheetname="Sheet1",withoids=FALSE,pguser="username",db='databasename',ip='ipaddress',source_file="STDIN",datecol=NULL,nrowscsv=10000,pgpath=c('c:\\pgutils\\psql')){
  if (!require(RODBC)) install.packages('RODBC'); require(RODBC) # for getSqlTypeInfo
  table=paste(schema,".",tablename,sep="")
  
  ext<-substr(inputfilepath,nchar(inputfilepath)-2,nchar(inputfilepath))
  #print(ext)
  
  if (ext=="dbf"){
    require(foreign)
    data<-read.dbf(inputfilepath,as.is=TRUE)
    csvfilename=sub(".dbf",".csv",basename(inputfilepath))
    csvfilename=paste(getwd(),csvfilename,sep="/")
    write.csv(data,csvfilename,row.names=FALSE,na="")
  }
  else if (ext=="csv" || ext=="txt"){
    #or from csv originally
    csvfilename<-inputfilepath
    data<-read.csv(csvfilename,stringsAsFactors=FALSE,header=header,strip.white=TRUE,nrows=nrowscsv)
    names(data)<-gsub("\\.","_",names(data))
    names(data)<-gsub("_+","_",names(data))
  }
  else if (ext=="xls"){
    odbcf<-odbcConnectExcel(inputfilepath)
    data<-sqlFetch(odbcf,sheetname,as.is=TRUE)
    csvfilename=sub(".xls",".csv",basename(inputfilepath))
    csvfilename=paste(getwd(),csvfilename,sep="/")
    write.csv(data,csvfilename,row.names=FALSE,na="")
  }
  else print("Unknown extension")
  
  names(data)<-tolower(names(data))
  
  if (length(pk)>0) {
    if (class(pk) %in% c("integer","numeric")) pk=paste(names(data)[pk],collapse=",")
  }
  
  datatypes<-getSqlTypeInfo("PostgreSQL")
  datatypes["numeric"]<-"numeric"
  
  csvfilename=gsub("\\\\","\\\\\\\\",csvfilename)
  
  text=""
  text=paste(text,"CREATE TABLE ",table," (",sep="")
  columnnames<-names(data)
  
  #################################################################################
  
  if (length(pk)>0) {
    for (n in columnnames) {
      if (length(grep(n, datecol))>0) {
        text=paste(text,"\"",n,"\" date,\n",sep="")
      } else {
        #print(class(data[[n]]))
        if (is.null(class(data[[n]]))) cat("Missing datatype:",class(data[[n]]),"\n")
        text=paste(text,"\"",n,"\" ",datatypes[[class(data[[n]])]],",\n",sep="")
      }
    }
    text=paste(text,"CONSTRAINT \"",table,"_pkey\" PRIMARY KEY (",pk,")\n",sep="")
  }
  
  if (length(pk)==0) {
    for (n in columnnames[1:(length(columnnames)-1)]) {
      if (length(grep(n, datecol))>0) {
        text=paste(text,"\"",n,"\" date,\n",sep="")
      } else {
        #print(class(data[[n]]))
        if (is.null(class(data[[n]]))) cat("Missing datatype:",class(data[[n]]),"\n")
        text=paste(text,"\"",n,"\" ",datatypes[[class(data[[n]])]],",\n",sep="")
      }
    }
    
    n=columnnames[length(columnnames)]
    text=paste(text,"\"",n,"\" ",datatypes[[class(data[[n]])]],sep="")
    #\"
  }
  
  ###############################################################################
  if (withoids) text=paste(text,") WITH (OIDS=TRUE);\n",sep="")
  else text=paste(text,") WITH (OIDS=FALSE);\n",sep="")
  text=paste(text,"ALTER TABLE ",table," OWNER TO ",pguser,";\n",sep="")
  
  
  
  
  if (source_file=="STDIN") {
    if (header) text=paste(text,"COPY ",table," FROM ",source_file," CSV HEADER;\n",sep="")
    else text=paste(text,"COPY ",table," FROM ",source_file," CSV;\n",sep="")
    
    sink("sqlquery.txt")
    cat(text)
    sink()
    
    
    
 
    if(length(grep('linux',sessionInfo()[[1]]$os)) == 1)
     {
      os <- 'linux'
     } else {
      os <- 'windows'
     }
    if (printcopy & os == 'linux')
    {
      cat(paste('ok the CREATE TABLE and COPY statements have been constructed for this file and is in "sqlquery.txt", have a look and see if it is correct\nif it is ok and you have not set your password to be remembered in pgpass then paste this into a cmd prompt\n\n cat sqlquery.txt \"',csvfilename,'\" | \"',pgpath,'\" -h ',ip,' -U ',pguser,' -d ',db,'\n\n\notherwise you can run this directly from R\n\n system(\"cat sqlquery.txt \\"',csvfilename,'\\" | \"',pgpath,'\" -h ',ip,' -U ',pguser,' -d ',db,'\")',sep=''),'\n')
      
      cat(paste("\n\nnow you probably should vaccuum the table\nVACUUM ANALYZE ",table,";\n",sep=""))
    } 
    if (!printcopy & os == 'linux')
    {
     
      system(paste('cat sqlquery.txt \"',csvfilename,'\" | psql -h ',ip,' -U ',pguser,' -d ',db,'',sep=''))
          
    }
    

    if (printcopy & os == 'windows')
    {
      cat(paste('ok the CREATE TABLE and COPY statements have been constructed for this file and is in "sqlquery.txt", have a look and see if it is correct\nif it is ok and you have not set your password to be remembered in pgAdmin then paste this into a cmd prompt\n\n type sqlquery.txt \"',csvfilename,'\" | \"',pgpath,'\" -h ',ip,' -U ',pguser,' -d ',db,'\n\n\notherwise you can run this directly from R\n\n system(\"type sqlquery.txt \\"',csvfilename,'\\" | \"',pgpath,'\" -h ',ip,' -U ',pguser,' -d ',db,'\")',sep=''),'\n')
      
      cat(paste("\n\nnow you probably should vaccuum the table\nVACUUM ANALYZE ",table,";\n",sep=""))
    } 
    if (!printcopy & os == 'windows')
    {
      sink('go.bat')
      cat(paste('type sqlquery.txt \"',csvfilename,'\" | \"',pgpath,'\" -h ',ip,' -U ',pguser,' -d ',db,'',sep=''))
      sink()
      shell('go.bat')
      file.remove('go.bat')
    }
    
    
  }
  
}

#+end_src

** sql_subset
*** test-sql_subset.r
#+name:test-sql_subset.r
#+begin_src R :session *R* :tangle tests/test-sql_subset.r :exports none :eval no
  
  ## install.packages("~/tools/swishdbtools_1.1_R_x86_64-pc-linux-gnu.tar.gz", repos = NULL, type = "source")
  require(swishdbtools)
  ##  ch <- connect2postgres('localhost', db='django', user='gislibrary', p='gislibrary')
  ## test_that('postgis data exists', {
  ##   expect_that(is.character(sqlquery_select(conn=ch, select='srid, srtext',x='spatial_ref_sys', limit = 2, subset = "srid = 4283", eval = F)), is_true())
  ##   expect_that(nrow(sqlquery_select(conn=ch, select='srid, srtext',x='spatial_ref_sys', limit = 2, subset = "srid = 4283", eval = T))==1, is_true())
  ## })
  
  #
  # dev tests
  source("R/sql_subset.r")
  source("R/pgListTables.r")
  if(!exists('p'))
  {
    p <- getPassword()
  }
   ch <- connect2postgres('115.146.84.135', db='ewedb', user='gislibrary', p=p)
   sql <- sql_subset(conn=ch, x='spatial_ref_sys',
                     subset = "srid = 4283", select='srid, srtext',
                     limit = 2, eval = T)
  ## cat(sql) # if eval=F
   nrow(sql)==1 # if eval=T
  source("R/sql_subset.r")
  #sql_subset(ch, 'airquality', 'Temp > 80', 'Ozone, Temp', eval = T,
  #           limit = 6)
  sql_subset(ch, 'dbsize', select = '*', into_table = 'temp101', eval=T)
  dbSendQuery(ch, 'drop table temp101')
  sql_subset(ch, 'dbsize', select = '*', eval=T)
  
#+end_src
*** R-sql_subset.r
#+name:sql_subset
#+begin_src R :session *R* :tangle R/sql_subset.r :exports none :eval no
################################################################
# name:sqlquery_select

sql_subset <- function(conn, x, subset = NA, select = "*",
                            schema = 'public',
                            limit = -1, eval = FALSE)
{
  # assume ch exists
  exists <- pgListTables(conn, schema, x)
  if(nrow(exists) == 0)
    {
      stop("Table doesn't exist.")
    }

  if(select=="*")
    {
      select <- names(
                     dbGetQuery(conn,
                      paste("select ", select, " from ",
                      schema, ".",
                      x, " limit 1",
                      sep = ""))
                     )
      select <- paste(select, collapse = ", ", sep = "")
    }

  sqlquery <- paste("select ", select, "\nfrom ", schema, ".",
                    x, "\n",
                    sep = "")

  if(!is.na(subset))
    {
      sqlquery <- paste(sqlquery, "where ", subset, "\n", sep = "")
    }

  if(limit > 0)
    {
      sqlquery <- paste(sqlquery, "limit ", limit, "\n", sep = "")
    }

  if(eval)
    {
      dat <- dbGetQuery(conn,sqlquery)
      return(dat)
    } else {
      return(sqlquery)
    }

}

#+end_src

*** man-sql_subset.Rd
#+name:sql_subset
#+begin_src R :session *R* :tangle man/sql_subset.Rd :exports none :eval no
\name{sql_subset}
\alias{sql_subset}
%- Also NEED an '\alias' for EACH other topic documented here.
\title{
sql_subset
}
\description{
Constructs an SQL query for a postgres database. Modelled on the base R function 'subset'.
}
\usage{
sql_subset(conn, x, subset, select, schema, limit, eval)
}
%- maybe also 'usage' for other objects documented here.
\arguments{
  \item{conn}{
%%     ~~Describe \code{remote} here~~
database connection
}
 \item{x}{
%%     ~~Describe \code{remote} here~~
the table name
}
 \item{subset}{
%%     ~~Describe \code{remote} here~~
the SQL 'where' statement
}
 \item{select}{
%%     ~~Describe \code{remote} here~~
which variables to include
}
 \item{schema}{
%%     ~~Describe \code{remote} here~~
the schema that has the table in it
}
 \item{limit}{
%%     ~~Describe \code{remote} here~~
limit, often useful for debugging
}
 \item{eval}{
%%     ~~Describe \code{remote} here~~
evaluate the query on the database?
}
}
\details{
%%  ~~ If necessary, more details than the description above ~~
}
\value{
%%  ~Describe the value returned
%%  If it is a LIST, use
%%  \item{comp1 }{Description of 'comp1'}
%%  \item{comp2 }{Description of 'comp2'}
%% ...
}
\references{
%% ~put references to the literature/web site here ~
}
\author{
ivanhanigan
}
\note{
%%  ~~further notes~~
}

%% ~Make other sections like Warning with \section{Warning }{....} ~

\seealso{
%% ~~objects to See Also as \code{\link{help}}, ~~~
}
\examples{
ch <- connect2postgres('115.146.84.135', db='ewedb',
                       user='gislibrary', p='gislibrary')
sql <- sql_subset(conn=ch, x='spatial_ref_sys',
                  subset = "srid = 4283", select='srid, srtext',
                  limit = 2, eval = T)
  
  
}
% Add one or more standard keywords, see file 'KEYWORDS' in the
% R documentation directory.
\keyword{ ~kwd1 }
\keyword{ ~kwd2 }% __ONLY ONE__ keyword per line

#+end_src


** sql_subset_into
*** test-sql_subset_into
#+name:test-sql_subset_into
#+begin_src R :session *R* :tangle tests/test-sql_subset_into.r :exports none :eval no
  source("R/connect2postgres.r")
  source("R/sql_subset.r")
  source("R/sql_subset_into.r")
  source("R/pgListTables.r")
  
  ch <- connect2postgres('115.146.84.135', db='ewedb', user='gislibrary', p='gislibrary')
  sql_subset_into(ch, 'dbsize',into_table='temp101', select = '*', eval=T)
  sql_subset(ch, 'temp101', eval = T)
  dbSendQuery(ch, 'drop table temp101')
  
#+end_src


*** R-sql_subset_into
#+name:sql_subset_into
#+begin_src R :session *R* :tangle R/sql_subset_into.r :exports none :eval no
  sql_subset_into <- function(conn, x, ..., into_schema = "public", into_table, eval = FALSE, drop = TRUE)
  {
    sql <- sql_subset(ch, x=x, ..., eval=F)
    sql <- gsub('from', paste("into ", into_schema, ".", into_table, "\nfrom ", sep = ""), sql)
    if(eval)
    {
      exists <- pgListTables(conn, into_schema, into_table)
      if(nrow(exists) > 0 & drop)
        {
          dbSendQuery(conn, paste("drop table ", into_schema, ".",
                                  into_table, sep =""))
        } else if (nrow(exists) > 0 & !drop)
          {
            stop("Table exists. Aborting.")
          }
    
      dbSendQuery(conn, sql)
      #dat <- dbGetQuery(conn, paste("select * from ", into_schema, ".", into_table, sep = ""))
      #return(dat)
    } else {
      return(sql)
    }
  }
    
#+end_src


** add_stdydscr
*** test-add_stdydscr
#+name:test-add_stdydscr
#+begin_src R :session *R* :tangle tests/test-add_stdydscr.r :exports none :eval no
  ################################################################
  # name:test-add_stdydscr
  source("R/connect2oracle.r")
  source("R/add_stdydscr.r")
  source("R/getPassword.r")
  
  pwd <- getPassword(remote=T)
  ch <- connect2oracle('115.146.93.225', db="DDIINDEXDB", p = pwd)
  
  stdy <- add_stdydscr(idno='TESTSTUDY', 'A TEST OF THE DDI FUNCTION',
                       ask = T)
  t(stdy)
  
  
#+end_src

*** R-add_stdydscr
#+name:add_stdydscr
#+begin_src R :session *R* :tangle R/add_stdydscr.r :exports none :eval no
  t################################################################
  # name:add_stdydscr
  
  add_stdydscr <- function(idno=NA,titl=NA,abstract=NA,authoring_entity_of_data=NA,
  distrbtr='NCEPH data manager',bibliographic_citation=NA,notes='NCEPH Unrestricted', restrctn=NA,datakind='OTHER',ask=F){
  if (!require(sqldf)) install.packages('sqldf')
  require(sqldf)
  if (!require(R2HTML)) install.packages('R2HTML')
  require(R2HTML)
    
    elements = c('TITL','IDNO','PRODUCER','PRODDATEDOC','BIBLCITDOC','AUTHENTY','COPYRIGHT','PRODDATESTDY','FUNDAG','DISTRBTR','SERNAME','VERSION','BIBLCITSTDY','TIMEPRD','COLLDATE','GEOGCOVER','GEOGUNIT','ANLYUNIT','UNIVERSE','DATAKIND','CLEANOPS','CONFDEC','SPECPERM','RESTRCTN','NOTES','ABSTRACT')
    
    stdydscr=as.data.frame(matrix(nrow=1,ncol=length(elements), byrow=TRUE))
    names(stdydscr)=elements
    if(is.na(titl)) {titl<- readline('title of study: ')}
    stdydscr$TITL =titl
    if(is.na(idno)) {idno<- readline('ID code of study: ')}
    stdydscr$IDNO =idno
    if(is.na(abstract)) {abstract<- readline('abstract: ')}
    stdydscr$ABSTRACT =abstract
    if(is.na(authoring_entity_of_data)) {authoring_entity_of_data<- readline('authoring_entity_of_data: ')}
    stdydscr$AUTHENTY =authoring_entity_of_data
    # auto
    stdydscr$PRODDATEDOC =Sys.Date()
    
    if(ask==F){
      stdydscr$PRODUCER =''
      
      stdydscr$BIBLCITDOC =''
      stdydscr$COPYRIGHT =''
      stdydscr$PRODDATESTDY =''
      stdydscr$FUNDAG =''
      stdydscr$DISTRBTR = distrbtr
      stdydscr$SERNAME =''
      stdydscr$VERSION =''
      stdydscr$BIBLCITSTDY =bibliographic_citation
      stdydscr$TIMEPRD =''
      stdydscr$COLLDATE =''
      stdydscr$GEOGCOVER =''
      stdydscr$GEOGUNIT =''
      stdydscr$ANLYUNIT =''
      stdydscr$UNIVERSE =''
      stdydscr$DATAKIND =datakind
      stdydscr$CLEANOPS =''
      stdydscr$CONFDEC =''
      stdydscr$SPECPERM =''
      stdydscr$RESTRCTN =restrctn
      stdydscr$NOTES =notes
      
    } else {
      for(i in c(7:(length(elements)-1))){
        element=elements[i]
        stdydscr[1,i]=readline(paste("enter descriptions for the ",element,": "))
      }
    }
    stdydscr$PRODDATESTDY <- format(as.Date( substr(stdydscr$PRODDATESTDY,1,10),'%Y-%m-%d'),"%d/%b/%Y")
    stdydscr$PRODDATEDOC <- format(as.Date( substr(stdydscr$PRODDATEDOC,1,10),'%Y-%m-%d'),"%d/%b/%Y")



    # TASK add a caveat that if NOTES is null then NCEPH Unrestricted
    return(stdydscr)
  }
  
  
#+end_src
** add_filedscr
*** test-add_filedscr
#+name:test-add_stdydscr
#+begin_src R :session *R* :tangle tests/test-add_filedscr.r :exports none :eval no
  ################################################################
  # name:test-add_stdydscr
  
  source("R/add_filedscr.r")
   
  file <- add_filedscr(fileid = 1, idno = 'TESTSTUDY', ask=T)
  
  t(file)
  
  
#+end_src
*** R-add_filedscr
#+name:add_filedscr
#+begin_src R :session *R* :tangle R/add_filedscr.r :exports none :eval no
################################################################
# name:add_filedscr
add_filedscr <- function(fileid=NA,idno=NA,filename=NA,notes='NCEPH_Unrestricted',filelocation=NA,file_description='',ask=F){
  if (!require(sqldf)) install.packages('sqldf')
  require(sqldf)
  if (!require(R2HTML)) install.packages('R2HTML')
  require(R2HTML)
    
  elements = c('IDNO','FILENAME','FILETYPE','PROCSTAT','SPECPERMFILE','DATEARCHIVED','DATEDESTROY','FILEDSCR','NOTES','REQID','PUBLISHDDI','BACKUPVALID','DATEBACKUPVALID','CHECKED','BACKUPLOCATION')
  filedscr=as.data.frame(matrix(nrow=1,ncol=length(elements), byrow=TRUE))
  names(filedscr)=elements
  stopifnot(!is.na(idno)) 
  filedscr$IDNO =idno
  if(is.na(fileid)) {fileid<- readline('fileid, one number for each file in the study: ')}
  filedscr$FILEID =fileid
  if(is.na(filename)) {filename<- readline('filename: ')}
  filedscr$FILENAME =filename
  if(is.na(notes)) {notes<- readline('notes: ')}
  filedscr$NOTES =notes
  if(is.na(filelocation)) {filelocation <- getwd()}
  filedscr$FILELOCATION =filelocation
  if(is.na(file_description)) {file_description<- readline('file_description: ')}
  filedscr$FILEDSCR=file_description
  
  if(ask==F){
    filedscr$FILETYPE =''
    filedscr$PROCSTAT =''
    filedscr$SPECPERMFILE =''
    filedscr$DATEARCHIVED =''
    filedscr$DATEDESTROY =''
    filedscr$REQID =''
    filedscr$PUBLISHDDI =''
    filedscr$BACKUPVALID =''
    filedscr$DATEBACKUPVALID =''
    filedscr$CHECKED =''
    filedscr$BACKUPLOCATION =''
  } else {
    for(i in 3:length(elements)){
      element=elements[i]
      filedscr[1,i]=readline(paste("enter descriptions for the ",element,": "))
    }
  }
  
  return(filedscr)
}

#+end_src

** load2ddiindex
*** test-load2ddiindex
#+name:test-load2ddiindex
#+begin_src R :session *R* :tangle tests/test-load2ddiindex.r :exports none :eval no
  ################################################################
  # name:test-load2ddiindex
  source("R/connect2oracle.r")
  source("R/add_stdydscr.r")
  source("R/getPassword.r")
  source("R/load2ddiindex.r")
  
  pwd <- getPassword(remote=T)
  ch <- connect2oracle('115.146.93.225', db="DDIINDEXDB", p = pwd)
  if(!exists('stdy'))
  {
    stdy <- add_stdydscr(ask = T)
  }
  t(stdy)
  
  load2ddiindex_study(conn = ch, stdy)
  load2ddiindex_file(conn = ch, file)
  
#+end_src

*** R-load2ddiindex
#+name:load2ddiindex
#+begin_src R :session *R* :tangle R/load2ddiindex.r :exports none :eval no
  ################################################################
  # name:load2ddiindex
  load2ddiindex_study <- function(conn=NA, stdydscr)
  {
  
    if(exists('stdydscr'))
      {
        stdyexists <- dbGetQuery(conn,
                  paste("select * from stdydscr where idno = '",stdydscr$IDNO,"'", sep="")
                  )
      if(nrow(stdyexists) > 0) stop('Study record already exists.')
      
  
    dbSendUpdate(conn,
    #   cat(
      paste('
      insert into STDYDSCR (',paste(names(stdydscr), sep = '', collapse = ', '),')
      VALUES (',paste("'",paste(gsub("'","",ifelse(is.na(stdydscr),'',stdydscr)),sep='',collapse="', '"),"'",sep=''),')',sep='')
      )
    }
  }
  
  
  load2ddiindex_file <- function(conn=NA, filedscr)
  {
  
  
  
    if(exists('filedscr'))
      {
      fileexists <- dbGetQuery(conn,
                  paste("select * from filedscr where filename = '",filedscr$FILENAME,"' and filelocation ='",filedscr$FILELOCATION,"'", sep="")
                  )
      if(nrow(fileexists) > 0) stop('File record already exists.')
      
    dbSendUpdate(ch,
    # cat(
      paste('
      insert into FILEDSCR (',paste(names(filedscr), sep = '', collapse = ', '),')
      VALUES (',paste("'",paste(gsub("'","",ifelse(is.na(filedscr),'',filedscr)),sep='',collapse="', '"),"'",sep=''),')',sep='')
    )
  
      }
  }
  
#+end_src
