#+TITLE:swishdbtools overview 
#+AUTHOR: Ivan Hanigan
#+email: ivan.hanigan@anu.edu.au
#+LaTeX_CLASS: article
#+LaTeX_CLASS_OPTIONS: [a4paper]
#+LATEX: \tableofcontents
-----

* Introduction
* functions
** sql_subset
*** test-sql_subset.r
#+name:test-sql_subset.r
#+begin_src R :session *R* :tangle tests/test-sql_subset.r :exports none :eval no
  
  ## install.packages("~/tools/swishdbtools_1.1_R_x86_64-pc-linux-gnu.tar.gz", repos = NULL, type = "source")
  require(swishdbtools)
  ##  ch <- connect2postgres('localhost', db='django', user='gislibrary', p='gislibrary')
  ## test_that('postgis data exists', {
  ##   expect_that(is.character(sqlquery_select(conn=ch, select='srid, srtext',x='spatial_ref_sys', limit = 2, subset = "srid = 4283", eval = F)), is_true())
  ##   expect_that(nrow(sqlquery_select(conn=ch, select='srid, srtext',x='spatial_ref_sys', limit = 2, subset = "srid = 4283", eval = T))==1, is_true())
  ## })
  
  #
  # dev tests
  source("R/sql_subset.r")
  source("R/pgListTables.r")
  
   ch <- connect2postgres('115.146.84.135', db='ewedb', user='gislibrary', p='gislibrary')
   sql <- sql_subset(conn=ch, x='spatial_ref_sys',
                     subset = "srid = 4283", select='srid, srtext',
                     limit = 2, eval = T)
  ## cat(sql) # if eval=F
   nrow(sql)==1 # if eval=T
  #### from subset man page ####
  # head(subset(airquality, Temp > 80, select = c(Ozone, Temp)))
  # str(airquality)
  # tempdata <- airquality
  # names(tempdata) <- tolower(names(tempdata))
  # names(tempdata) <- gsub('\\.', '_',names(tempdata))
  # str(tempdata)
  # dbWriteTable(ch, 'airquality', tempdata)
  # rm(tempdata)
  source("R/sql_subset.r")
  #sql_subset(ch, 'airquality', 'Temp > 80', 'Ozone, Temp', eval = T)
  sql_subset(ch, 'dbsize', select = '*', into_table = 'temp101', eval=T)
  dbSendQuery(ch, 'drop table temp101')
  sql_subset(ch, 'dbsize', select = '*', eval=T)
  
#+end_src
*** R-sql_subset.r
#+name:sql_subset
#+begin_src R :session *R* :tangle R/sql_subset.r :exports none :eval no
################################################################
# name:sqlquery_select

sql_subset <- function(conn, x, subset = NA, select = "*",
                            schema = 'public',
                            limit = -1, eval = FALSE)
{
  # assume ch exists
  exists <- pgListTables(conn, schema, x)
  if(nrow(exists) == 0)
    {
      stop("Table doesn't exist.")
    }

  if(select=="*")
    {
      select <- names(
                     dbGetQuery(conn,
                      paste("select ", select, " from ",
                      schema, ".",
                      x, " limit 1",
                      sep = ""))
                     )
      select <- paste(select, collapse = ", ", sep = "")
    }

  sqlquery <- paste("select ", select, "\nfrom ", schema, ".",
                    x, "\n",
                    sep = "")

  if(!is.na(subset))
    {
      sqlquery <- paste(sqlquery, "where ", subset, "\n", sep = "")
    }

  if(limit > 0)
    {
      sqlquery <- paste(sqlquery, "limit ", limit, "\n", sep = "")
    }

  if(eval)
    {
      dat <- dbGetQuery(conn,sqlquery)
      return(dat)
    } else {
      return(sqlquery)
    }

}

#+end_src

*** man-sql_subset.Rd
#+name:sql_subset
#+begin_src R :session *R* :tangle man/sql_subset.Rd :exports none :eval no
\name{sql_subset}
\alias{sql_subset}
%- Also NEED an '\alias' for EACH other topic documented here.
\title{
sql_subset
}
\description{
Constructs an SQL query for a postgres database. Modelled on the base R function 'subset'.
}
\usage{
sql_subset(conn, x, subset, select, schema, limit, eval)
}
%- maybe also 'usage' for other objects documented here.
\arguments{
  \item{conn}{
%%     ~~Describe \code{remote} here~~
database connection
}
 \item{x}{
%%     ~~Describe \code{remote} here~~
the table name
}
 \item{subset}{
%%     ~~Describe \code{remote} here~~
the SQL 'where' statement
}
 \item{select}{
%%     ~~Describe \code{remote} here~~
which variables to include
}
 \item{schema}{
%%     ~~Describe \code{remote} here~~
the schema that has the table in it
}
 \item{limit}{
%%     ~~Describe \code{remote} here~~
limit, often useful for debugging
}
 \item{eval}{
%%     ~~Describe \code{remote} here~~
evaluate the query on the database?
}
}
\details{
%%  ~~ If necessary, more details than the description above ~~
}
\value{
%%  ~Describe the value returned
%%  If it is a LIST, use
%%  \item{comp1 }{Description of 'comp1'}
%%  \item{comp2 }{Description of 'comp2'}
%% ...
}
\references{
%% ~put references to the literature/web site here ~
}
\author{
ivanhanigan
}
\note{
%%  ~~further notes~~
}

%% ~Make other sections like Warning with \section{Warning }{....} ~

\seealso{
%% ~~objects to See Also as \code{\link{help}}, ~~~
}
\examples{
ch <- connect2postgres('115.146.84.135', db='ewedb',
                       user='gislibrary', p='gislibrary')
sql <- sql_subset(conn=ch, x='spatial_ref_sys',
                  subset = "srid = 4283", select='srid, srtext',
                  limit = 2, eval = T)
  
  
}
% Add one or more standard keywords, see file 'KEYWORDS' in the
% R documentation directory.
\keyword{ ~kwd1 }
\keyword{ ~kwd2 }% __ONLY ONE__ keyword per line

#+end_src


** sql_subset_into
*** test-sql_subset_into
#+name:test-sql_subset_into
#+begin_src R :session *R* :tangle tests/test-sql_subset_into.r :exports none :eval no
  source("R/connect2postgres.r")
  source("R/sql_subset.r")
  source("R/sql_subset_into.r")
  source("R/pgListTables.r")
  
  ch <- connect2postgres('115.146.84.135', db='ewedb', user='gislibrary', p='gislibrary')
  sql_subset_into(ch, 'dbsize',into_table='temp101', select = '*', eval=T)
  sql_subset(ch, 'temp101', eval = T)
  dbSendQuery(ch, 'drop table temp101')
  
#+end_src


*** R-sql_subset_into
#+name:sql_subset_into
#+begin_src R :session *R* :tangle R/sql_subset_into.r :exports none :eval no
  sql_subset_into <- function(conn, x, ..., into_schema = "public", into_table, eval = FALSE, drop = TRUE)
  {
    sql <- sql_subset(ch, x=x, ..., eval=F)
    sql <- gsub('from', paste("into ", into_schema, ".", into_table, "\nfrom ", sep = ""), sql)
    if(eval)
    {
      exists <- pgListTables(conn, into_schema, into_table)
      if(nrow(exists) > 0 & drop)
        {
          dbSendQuery(conn, paste("drop table ", into_schema, ".",
                                  into_table, sep =""))
        } else if (nrow(exists) > 0 & !drop)
          {
            stop("Table exists. Aborting.")
          }
    
      dbSendQuery(conn, sql)
      #dat <- dbGetQuery(conn, paste("select * from ", into_schema, ".", into_table, sep = ""))
      #return(dat)
    } else {
      return(sql)
    }
  }
    
#+end_src

** add_stdydscr
*** test-add_stdydscr
#+name:test-add_stdydscr
#+begin_src R :session *R* :tangle tests/test-add_stdydscr.r :exports none :eval no
################################################################
# name:test-add_stdydscr
  source("R/connect2oracle.r")
  source("R/add_stdydscr.r")
  source("R/sql_subset_into.r")
  source("R/pgListTables.r")
  
  ch <- connect2postgres('115.146.84.135', db='ewedb', user='gislibrary', p='gislibrary')
  sql_subset_into(ch, 'dbsize',into_table='temp101', select = '*', eval=T)

#+end_src

*** R-add_stdydscr
#+name:add_stdydscr
#+begin_src R :session *R* :tangle R/add_stdydscr.r :exports none :eval no
################################################################
# name:add_stdydscr

add_stdydscr <- function(idno=NA,titl=NA,abstract=NA,authoring_entity_of_data=NA,
distrbtr='NCEPH data manager',bibliographic_citation=NA,notes='NCEPH Unrestricted', restrctn=NA,datakind='OTHER',ask=F){
if (!require(sqldf)) install.packages('sqldf')
require(sqldf)
if (!require(R2HTML)) install.packages('R2HTML')
require(R2HTML)
  
  elements = c('TITL','IDNO','PRODUCER','PRODDATEDOC','BIBLCITDOC','AUTHENTY','COPYRIGHT','PRODDATESTDY','FUNDAG','DISTRBTR','SERNAME','VERSION','BIBLCITSTDY','TIMEPRD','COLLDATE','GEOGCOVER','GEOGUNIT','ANLYUNIT','UNIVERSE','DATAKIND','CLEANOPS','CONFDEC','SPECPERM','RESTRCTN','NOTES','ABSTRACT')
  
  stdydscr=as.data.frame(matrix(nrow=1,ncol=length(elements), byrow=TRUE))
  names(stdydscr)=elements
  if(is.na(titl)) {titl<- readline('title of study: ')}
  stdydscr$TITL =titl
  if(is.na(idno)) {idno<- readline('ID code of study: ')}
  stdydscr$IDNO =idno
  if(is.na(abstract)) {abstract<- readline('abstract: ')}
  stdydscr$ABSTRACT =abstract
  if(is.na(authoring_entity_of_data)) {authoring_entity_of_data<- readline('authoring_entity_of_data: ')}
  stdydscr$AUTHENTY =authoring_entity_of_data
  # auto
  stdydscr$PRODDATEDOC =Sys.Date()
  
  if(ask==F){
    stdydscr$PRODUCER =''
    
    stdydscr$BIBLCITDOC =''
    stdydscr$COPYRIGHT =''
    stdydscr$PRODDATESTDY =''
    stdydscr$FUNDAG =''
    stdydscr$DISTRBTR = distrbtr
    stdydscr$SERNAME =''
    stdydscr$VERSION =''
    stdydscr$BIBLCITSTDY =bibliographic_citation
    stdydscr$TIMEPRD =''
    stdydscr$COLLDATE =''
    stdydscr$GEOGCOVER =''
    stdydscr$GEOGUNIT =''
    stdydscr$ANLYUNIT =''
    stdydscr$UNIVERSE =''
    stdydscr$DATAKIND =datakind
    stdydscr$CLEANOPS =''
    stdydscr$CONFDEC =''
    stdydscr$SPECPERM =''
    stdydscr$RESTRCTN =restrctn
    stdydscr$NOTES =notes
    
  } else {
    for(i in c(7:(length(elements)-1))){
      element=elements[i]
      stdydscr[1,i]=readline(paste("enter descriptions for the ",element,": "))
    }
  }
  # TASK add a caveat that if NOTES is null then NCEPH Unrestricted
  return(stdydscr)
}


#+end_src
